---
title: "Group Fairness Model"
author: "Simon Schrauth"
date: "`r Sys.Date()`"
output: html_document
---
# Group Fairness

## Goal

After executing this script, the group fairness/discrimination of the base model should be determined.

## Preparation
### Install packages
```{r}
pacman::p_load(devtools,
               tidyverse, 
               here,
               tidymodels,
               DALEXtra,
               fairmodels,
               wesanderson,
               knitr,
               kableExtra,
               magick)

tidymodels_prefer()
```

### Load data
```{r}
data = readRDS(here("01_data", "02_data_processed", "01_base_model",
                    "03_data.rds"))

model_fit = readRDS(file = here("01_data", "02_data_processed", "01_base_model",
                                "04_model_fit.rds"))
```

## Group Fairness
### Basic model explanation
```{r}
data_group = data %>% 
  mutate(sex = factor(ifelse(sex == "Male", "Männlich", "Weiblich")),
         race = factor(case_when(
                  race == "Caucasian" ~ "Weiß",
                  race == "African-American" ~ "Schwarz",
                  race == "Hispanic" ~ "Hispanisch",
                  race == "Other" ~ "Andere"
                                )
                      )
         )

recipe = recipe(compas ~ .,
                data = data_group) %>% 
  step_dummy(all_nominal_predictors())

model = logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")

workflow = workflow() %>% 
  add_model(model) %>% 
  add_recipe(recipe)

model_fit = 
  workflow %>% 
  fit(data = data_group)

y = model_fit$pre$mold$outcomes %>% 
  as.vector() %>% 
  unlist(use.names = FALSE) %>% 
  as.numeric()

model_base_explainer = explain_tidymodels(model = model_fit,
                                          data = data_group,
                                          y = y-1,
                                          label = "Original-Model")

colors = wesanderson::wes_palette("Darjeeling1")
```

### Group Fairness for Sex
```{r}
base_fairobj_sex = fairness_check(model_base_explainer,
                                  protected  = data_group$sex,
                                  privileged = "Männlich")

plot_base_sex = plot(base_fairobj_sex, fairness_metrics = c("STP", "TPR", "PPV")) +
  facet_wrap(~ factor(metric, levels = c("Statistical parity ratio   (TP + FP)/(TP + FP + TN + FN)",
                                         "Equal opportunity ratio     TP/(TP + FN)",
                                         "Predictive parity ratio     TP/(TP + FP)"),
                      labels = c("Statistical Parity \n(Equal Positive Rate)",
                                 "Equal Opportunity \n(Equal TPR)",
                                 "Predictive Parity \n(Equal Precision)")
                      ), ncol = 1) +
  labs(title = "Gruppen-Fairness in Bezug auf Geschlecht",
       subtitle = "für Original-Modell",
       y = "Verhältnis Weiblich/Männlich",
       x = "Geschlecht") +
  theme(axis.text.y = element_blank()) +
  scale_fill_manual(values = colors[5]) +
  guides(fill = "none") +
  theme_gray(base_size = 13)

plot_base_sex$layers[[1]]$aes_params$fill <- colors[2]
plot_base_sex$layers[[2]]$aes_params$fill <- colors[1]
plot_base_sex$layers[[3]]$aes_params$fill <- colors[1]
```

```{r}
plot_dens_base_sex = plot_density(base_fairobj_sex) +
    scale_fill_manual(values = colors[c(2,3)]) +
    guides(fill = "none") +
    theme_gray(base_size = 13) +
    labs(title = "Dichte-Verteilung für Geschlecht",
         subtitle = "für Original-Modell",
         x = "Wahrscheinlichkeit für niedrigen COMPAS-Score",
         y = "Geschlecht")
```


### Group Fairness for Race
```{r}
base_fairobj_race = fairness_check(model_base_explainer,
                                   protected  = data_group$race,
                                   privileged = "Weiß")

plot_base_race = plot(base_fairobj_race, fairness_metrics = c("STP", "TPR", "PPV")) +
  facet_wrap(~ factor(metric, levels = c("Statistical parity ratio   (TP + FP)/(TP + FP + TN + FN)",
                                         "Equal opportunity ratio     TP/(TP + FN)",
                                         "Predictive parity ratio     TP/(TP + FP)"),
                      labels = c("Statistical Parity \n(Equal Positive Rate)",
                                 "Equal Opportunity \n(Equal TPR)",
                                 "Predictive Parity \n(Equal Precision)")
                      ), ncol = 1) +
  labs(title = "Gruppen-Fairness in Bezug auf Race",
       subtitle = "für Original-Modell",
       y = "Verhältnis unprivilegierte Race-Gruppe/Weiß",
       x = "unprivilegierte Race-Gruppe") +
  scale_fill_manual(values = colors[5]) +
  guides(fill = "none") +
  theme_gray(base_size = 13)

plot_base_race$layers[[1]]$aes_params$fill <- colors[2]
plot_base_race$layers[[2]]$aes_params$fill <- colors[1]
plot_base_race$layers[[3]]$aes_params$fill <- colors[1]
```

```{r}
plot_dens_base_race = plot_density(base_fairobj_race) +
    scale_fill_manual(values = colors[c(5,4,1,2)]) +
    guides(fill = "none") +
    theme_gray(base_size = 13) +
    labs(title = "Dichte-Verteilung für Race",
         subtitle = "für Original-Modell",
         x = "Wahrscheinlichkeit für niedrigen COMPAS-Score",
         y = "Race")
```


## Pre-Processing
### Reweighing for Sex
```{r}
weights_sex = reweight(protected = data_group$sex,
                       y = as.numeric(data_group$compas)-1)

data_sex = data_group %>% 
  mutate(weights = importance_weights(weights_sex)) %>% 
  mutate(race = fct_relevel(race, c("Weiß", "Schwarz", "Hispanisch", "Andere")))

recipe_sex = recipe(compas ~ .,
                    data = data_sex) %>% 
  step_dummy(all_nominal_predictors())

model_sex = logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")

workflow_sex = workflow() %>% 
  add_model(model_sex) %>% 
  add_recipe(recipe_sex) %>% 
  add_case_weights(weights)

model_fit_sex = workflow_sex %>% 
  fit(data = data_sex)

estimation_sex = tidy(model_fit_sex, exponentiate = TRUE)

estimation_sex_nice = estimation_sex %>% 
    slice(-1) %>% 
    mutate(term = case_when(
      term == "age" ~ "Alter",
      term == "days_in_jail" ~ "Tage im Gefängnis",
      term == "juv_fel_count" ~ "Straftaten (jugendl.)",
      term == "juv_misd_count" ~ "Ordnungswidr. (jugendl.)",
      term == "juv_other_count" ~ "Andere Anzeigen (jugendl.)",
      term == "priors_count" ~ "Anzahl Straftaten",
      term == "sex_Weiblich" ~ "Geschlecht: Weiblich",
      term == "race_Schwarz" ~ "Race: Schwarz",
      term == "race_Hispanisch" ~ "Race: Hispanisch",
      term == "race_Andere" ~ "Race: Andere",
      term == "charge_degree_M" ~ "Schwere der Straftat: Ordnungswidr.",
      term == "two_year_recid_yes" ~ "Rückfälligkeit: Ja",
      .default = term
        )
      ) %>% 
    column_to_rownames(var = "term") %>% 
    mutate(estimate_percent = percent(estimate-1, accuracy = 0.1)) %>% 
    relocate(estimate_percent, .after = estimate) %>% 
    rename("Schätzer" = estimate,
           "Schätzer (in Prozent)" = estimate_percent,
           Standardfehler = std.error,
           "z-Wert" = statistic,
           "p-Wert" = p.value)

kable(estimation_sex_nice, booktabs = TRUE, 
      align = "c", 
      digits = c(3, 1, 3, 2, 4)) %>% 
  row_spec(seq(1, nrow(estimation_sex_nice), 2), background = "#f8f8f8") %>% 
  kable_styling() %>% 
  save_kable(file = here("03_outputs", "03_group", "09_table_rew_sex.png"),
             density = 500)
```

### Group Fairness for sex-reweighted model
```{r}
y_sex = model_fit_sex$pre$mold$outcomes %>% 
  as.vector() %>% 
  unlist(use.names = FALSE) %>% 
  as.numeric()

model_sex_explainer = explain_tidymodels(model = model_fit_sex,
                                          data = data_group,
                                          y = y_sex-1,
                                          label = "Pre-processed Modell")

rew_fairobj_sex = fairness_check(model_base_explainer, model_sex_explainer,
                                 protected  = data_sex$sex,
                                 privileged = "Männlich")

plot_rew_sex = plot(rew_fairobj_sex, fairness_metrics = c("STP", "TPR", "PPV")) +
  facet_wrap(~ factor(metric, levels = c("Statistical parity ratio   (TP + FP)/(TP + FP + TN + FN)",
                                         "Equal opportunity ratio     TP/(TP + FN)",
                                         "Predictive parity ratio     TP/(TP + FP)"),
                      labels = c("Statistical Parity \n(Equal Positive Rate)",
                                 "Equal Opportunity \n(Equal TPR)",
                                 "Predictive Parity \n(Equal Precision)")
                      ), ncol = 1) +
  labs(title = "Gruppen-Fairness in Bezug auf Geschlecht",
       subtitle = "für Original-Modell & Modell korrigiert für Geschlecht",
       y = "Verhältnis Weiblich/Männlich",
       x = "",
       fill = "") +
  theme(axis.text.y = element_blank()) +
  scale_fill_manual(values = colors[c(5,3)]) +
  theme_gray(base_size = 13) +
  theme(legend.position = "top")

plot_rew_sex$layers[[1]]$aes_params$fill <- colors[2]
plot_rew_sex$layers[[2]]$aes_params$fill <- colors[1]
plot_rew_sex$layers[[3]]$aes_params$fill <- colors[1]
```

```{r}
plot_dens_rew_sex = plot_density(rew_fairobj_sex) +
    scale_fill_manual(values = colors[c(2,3)]) +
    guides(fill = "none") +
    theme_gray(base_size = 13) +
    labs(title = "Dichte-Verteilung für Geschlecht",
         subtitle = "für Original-Modell & Modell korrigiert für Geschlecht",
         x = "Wahrscheinlichkeit für niedrigen COMPAS-Score",
         y = "Geschlecht")
```


### Reweighing for Race
```{r}
weights_race = reweight(protected = data_group$race,
                        y = as.numeric(data_group$compas)-1)

data_race = data_group %>% 
  mutate(weights = importance_weights(weights_race)) %>% 
  mutate(race = fct_relevel(race, c("Weiß", "Schwarz", "Hispanisch", "Andere")))

recipe_race = recipe(compas ~ .,
                     data = data_race) %>% 
  step_dummy(all_nominal_predictors())

model_race = logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")

workflow_race = workflow() %>% 
  add_model(model_race) %>% 
  add_recipe(recipe_race) %>% 
  add_case_weights(weights)

model_fit_race = workflow_race %>% 
  fit(data = data_race)

estimation_race = tidy(model_fit_race, exponentiate = TRUE)

estimation_race %>% 
  slice(-1) %>% 
  mutate(estimate_percent = percent((estimate - 1), digits = 1)) %>% 
  relocate(estimate_percent, .after = estimate)

estimation_race_nice = estimation_race %>% 
    slice(-1) %>% 
    mutate(term = case_when(
      term == "age" ~ "Alter",
      term == "days_in_jail" ~ "Tage im Gefängnis",
      term == "juv_fel_count" ~ "Straftaten (jugendl.)",
      term == "juv_misd_count" ~ "Ordnungswidr. (jugendl.)",
      term == "juv_other_count" ~ "Andere Anzeigen (jugendl.)",
      term == "priors_count" ~ "Anzahl Straftaten",
      term == "sex_Weiblich" ~ "Geschlecht: Weiblich",
      term == "race_Schwarz" ~ "Race: Schwarz",
      term == "race_Hispanisch" ~ "Race: Hispanisch",
      term == "race_Andere" ~ "Race: Andere",
      term == "charge_degree_M" ~ "Schwere der Straftat: Ordnungswidr.",
      term == "two_year_recid_yes" ~ "Rückfälligkeit: Ja",
      .default = term
        )
      ) %>% 
    column_to_rownames(var = "term") %>% 
    mutate(estimate_percent = percent(estimate-1, accuracy = 0.1)) %>% 
    relocate(estimate_percent, .after = estimate) %>% 
    rename("Schätzer" = estimate,
           "Schätzer (in Prozent)" = estimate_percent,
           Standardfehler = std.error,
           "z-Wert" = statistic,
           "p-Wert" = p.value)

kable(estimation_race_nice, booktabs = TRUE, 
      align = "c", 
      digits = c(3, 1, 3, 2, 4)) %>% 
  row_spec(seq(1, nrow(estimation_sex_nice), 2), background = "#f8f8f8") %>% 
  kable_styling() %>% 
  save_kable(file = here("03_outputs", "03_group", "10_table_rew_race.png"),
             density = 500)
```

### Group Fairness for race-reweighted model
```{r}
y_race = model_fit_race$pre$mold$outcomes %>% 
  as.vector() %>% 
  unlist(use.names = FALSE) %>% 
  as.numeric()

model_race_explainer = explain_tidymodels(model = model_fit_race,
                                          data = data_group,
                                          y = y_race-1,
                                          label = "Pre-processed Modell")

rew_fairobj_race = fairness_check(model_base_explainer, model_race_explainer,
                                  protected  = data_race$race,
                                  privileged = "Weiß")

plot_rew_race = plot(rew_fairobj_race, fairness_metrics = c("STP", "TPR", "PPV")) +
  facet_wrap(~ factor(metric, levels = c("Statistical parity ratio   (TP + FP)/(TP + FP + TN + FN)",
                                         "Equal opportunity ratio     TP/(TP + FN)",
                                         "Predictive parity ratio     TP/(TP + FP)"),
                      labels = c("Statistical Parity \n(Equal Positive Rate)",
                                 "Equal Opportunity \n(Equal TPR)",
                                 "Predictive Parity \n(Equal Precision)")
                      ), ncol = 1) +
  labs(title = "Gruppen-Fairness in Bezug auf Race",
       subtitle = "für durch Reweighing korrigiertes Modell",
       y = "Verhältnis unprivilegierte Race-Gruppe/Weiß",
       x = "unprivilegierte Race-Gruppe",
       fill = "")  +
  theme(axis.text.y = element_blank()) +
  scale_fill_manual(values = colors[c(5,3)]) +
  theme_gray(base_size = 13) +
  theme(legend.position = "top")

plot_rew_race$layers[[1]]$aes_params$fill <- colors[2]
plot_rew_race$layers[[2]]$aes_params$fill <- colors[1]
plot_rew_race$layers[[3]]$aes_params$fill <- colors[1]
```

```{r}
plot_dens_rew_race = plot_density(rew_fairobj_race) +
    scale_fill_manual(values = colors[c(5,4,1,2)]) +
    guides(fill = "none") +
    theme_gray(base_size = 13) +
    labs(title = "Dichte-Verteilung für Race",
         subtitle = "für Original-Modell & Modell korrigiert für Race",
         x = "Wahrscheinlichkeit für niedrigen COMPAS-Score",
         y = "Race")
```

## Save Plots
```{r}
ggsave("01_plot_base_sex.png",
       plot = plot_base_sex,
       device = "png",
       path = here("03_outputs", "03_group"),
       dpi = 300,
       width = 20,
       height = 20,
       units = c("cm")
       )

ggsave("02_plot_dens_base_sex.png",
       plot = plot_dens_base_sex,
       device = "png",
       path = here("03_outputs", "03_group"),
       dpi = 300,
       width = 20,
       height = 20,
       units = c("cm")
       )

ggsave("03_plot_base_race.png",
       plot = plot_base_race,
       device = "png",
       path = here("03_outputs", "03_group"),
       dpi = 300,
       width = 20,
       height = 20,
       units = c("cm")
       )

ggsave("04_plot_dens_base_race.png",
       plot = plot_dens_base_race,
       device = "png",
       path = here("03_outputs", "03_group"),
       dpi = 300,
       width = 20,
       height = 20,
       units = c("cm")
       )

ggsave("05_plot_rew_sex.png",
       plot = plot_rew_sex,
       device = "png",
       path = here("03_outputs", "03_group"),
       dpi = 300,
       width = 20,
       height = 20,
       units = c("cm")
       )

ggsave("06_plot_dens_rew_sex.png",
       plot = plot_dens_rew_sex,
       device = "png",
       path = here("03_outputs", "03_group"),
       dpi = 300,
       width = 20,
       height = 20,
       units = c("cm")
       )

ggsave("07_plot_rew_race.png",
       plot = plot_rew_race,
       device = "png",
       path = here("03_outputs", "03_group"),
       dpi = 300,
       width = 20,
       height = 20,
       units = c("cm")
       )

ggsave("08_plot_dens_rew_race.png",
       plot = plot_dens_rew_race,
       device = "png",
       path = here("03_outputs", "03_group"),
       dpi = 300,
       width = 20,
       height = 20,
       units = c("cm")
       )
```

